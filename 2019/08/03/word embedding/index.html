<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>word embedding | Huangjingjingblog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="word embedding https://www.bilibili.com/video/av56959021?from=search&amp;amp;seid=17230449452027579455   one-hot  bag of words    &amp;lt;word, count&amp;gt; map document similarity cosine：夹角 欧式距离 dot - product：点">
<meta name="keywords" content="word embedding">
<meta property="og:type" content="article">
<meta property="og:title" content="word embedding">
<meta property="og:url" content="http://yoursite.com/2019/08/03/word embedding/index.html">
<meta property="og:site_name" content="Huangjingjingblog">
<meta property="og:description" content="word embedding https://www.bilibili.com/video/av56959021?from=search&amp;amp;seid=17230449452027579455   one-hot  bag of words    &amp;lt;word, count&amp;gt; map document similarity cosine：夹角 欧式距离 dot - product：点">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="c:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564734550147.png">
<meta property="og:image" content="c:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564734451378.png">
<meta property="og:image" content="c:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564734822692.png">
<meta property="og:image" content="c:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564734878540.png">
<meta property="og:image" content="c:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564735198176.png">
<meta property="og:image" content="c:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564735494655.png">
<meta property="og:image" content="c:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564735577434.png">
<meta property="og:image" content="c:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564735884295.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190518114637829.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190518114710294.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2019051811474671.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lhc2luMA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190518114815763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lhc2luMA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190518114839403.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190518114939849.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190518115058979.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lhc2luMA==,size_16,color_FFFFFF,t_70">
<meta property="og:updated_time" content="2019-08-03T08:15:44.907Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="word embedding">
<meta name="twitter:description" content="word embedding https://www.bilibili.com/video/av56959021?from=search&amp;amp;seid=17230449452027579455   one-hot  bag of words    &amp;lt;word, count&amp;gt; map document similarity cosine：夹角 欧式距离 dot - product：点">
<meta name="twitter:image" content="c:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564734550147.png">
  
    <link rel="alternate" href="/atom.xml" title="Huangjingjingblog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Huangjingjingblog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">welcome</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-word embedding" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/08/03/word embedding/" class="article-date">
  <time datetime="2019-08-03T07:49:52.411Z" itemprop="datePublished">2019-08-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      word embedding
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="word-embedding"><a href="#word-embedding" class="headerlink" title="word embedding"></a>word embedding<img src="C:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564734550147.png" alt="1564734550147"></h1><blockquote>
<p><a href="https://www.bilibili.com/video/av56959021?from=search&amp;seid=17230449452027579455" target="_blank" rel="noopener">https://www.bilibili.com/video/av56959021?from=search&amp;seid=17230449452027579455</a></p>
</blockquote>
<ul>
<li><p>one-hot</p>
</li>
<li><p>bag of words  </p>
<ul>
<li>&lt;word, count&gt; map</li>
<li>document similarity<ul>
<li>cosine：夹角</li>
<li>欧式距离</li>
<li>dot - product：点乘</li>
<li>tf-idf: 每个单词对这个文本的重要性且不是对素有文本都重要</li>
</ul>
</li>
</ul>
</li>
<li><p>神经网络</p>
<ul>
<li><p>单词相似或相关</p>
<ul>
<li><p>词性</p>
</li>
<li><p>单词组合的频率高</p>
<p>[girl, women ,boy,man]-&gt;[gender,age]</p>
<p>任何东西都可以embedding</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<a id="more"></a>

<p><img src="C:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564734451378.png" alt="1564734451378"></p>
<p>NNLM ：根据上文推测下文</p>
<p>上文：feture</p>
<p>单词：label</p>
<p>相似的单词在空间中更</p>
<h2 id="word2vec"><a href="#word2vec" class="headerlink" title="word2vec"></a>word2vec</h2><p>CBOW</p>
<blockquote>
<p>一个单词的含义不是由自己决定，而是上下文</p>
<p>每个词都是由相邻的词决定的</p>
</blockquote>
<p><img src="C:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564734822692.png" alt="1564734822692"></p>
<p>skip-gram</p>
<blockquote>
<p> 根据单词，预测上下文</p>
<p>每个词都决定了相邻的词</p>
</blockquote>
<p><img src="C:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564734878540.png" alt="1564734878540"></p>
<ul>
<li><p>huffman encoding and Hierarchical softmax</p>
<p>权重大的词放前一点，减少运算量</p>
</li>
<li><p>负采样 negative Sampling</p>
<p>we <strong>play</strong> game(neg,<strong>eat</strong>)</p>
<p>算play的时候顺带把eat算了</p>
<p>softmax：激励函数（sigmoid）归类问题</p>
<p><img src="C:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564735198176.png" alt="1564735198176"></p>
</li>
</ul>
<h3 id="GloVe"><a href="#GloVe" class="headerlink" title="GloVe"></a>GloVe</h3><p>全局向量单词表示</p>
<p>上下文：全篇文章</p>
<p>不是滑动window，所以必须全部文章后才可以处理</p>
<h3 id="ELMo"><a href="#ELMo" class="headerlink" title="ELMo"></a>ELMo</h3><p>2018</p>
<p>动态embedding：3个embedding的权重可调整</p>
<p><img src="C:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564735494655.png" alt="1564735494655"></p>
<p>双层LSTM</p>
<p><img src="C:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564735577434.png" alt="1564735577434"></p>
<p>效果很好</p>
<h3 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h3><p>双向 编码 表示 from transformers （特征提取器）替代RNN</p>
<p>大大提高了文本的特征提取能力，可以更好的找到单词的关系</p>
<p>从上下文预测word - cbow</p>
<ul>
<li>masked language model</li>
</ul>
<p>训练过程中，随机去掉一些词，尽量让权重分散</p>
<p><img src="C:%5CUsers%5C10344%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1564735884295.png" alt="1564735884295"></p>
<p>TensorFlow hub</p>
<p>bert-as- service</p>
<p>推荐uncased</p>
<h3 id="万物皆可embedding"><a href="#万物皆可embedding" class="headerlink" title="万物皆可embedding"></a>万物皆可embedding</h3><ul>
<li>用一个低维的向量表示一个物体，可以是一个词，或是一个商品，或是一个电影等等</li>
<li>这个embedding向量的性质是能使距离相近的向量对应的物体有相近的含义</li>
<li>Embedding甚至还具有数学运算的关系<ul>
<li>比如Embedding（马德里）-Embedding（西班牙）+Embedding(法国)≈Embedding(巴黎)</li>
</ul>
</li>
</ul>
<h3 id="word2vec-1"><a href="#word2vec-1" class="headerlink" title="word2vec"></a>word2vec</h3><h3 id="Graph-Embedding"><a href="#Graph-Embedding" class="headerlink" title="Graph Embedding"></a>Graph Embedding</h3><blockquote>
<p><a href="https://blog.csdn.net/Yasin0/article/details/90313313" target="_blank" rel="noopener">https://blog.csdn.net/Yasin0/article/details/90313313</a></p>
</blockquote>
<h4 id="deepwalk"><a href="#deepwalk" class="headerlink" title="deepwalk"></a>deepwalk</h4><p>随机游走，将点的序列表示成文本</p>
<p>改进：根据概率游走</p>
<p><strong>阿里论文</strong></p>
<p>主要思想：在由物品组成的图结构上进行随机游走，产生大量物品序列，然后将这些物品序列作为训练样本输入word2vec进行训练，得到物品的embedding</p>
<p><img src="https://img-blog.csdnimg.cn/20190518114637829.png" alt="img"></p>
<p>b. 若产生了多条相同的有向边，则有向边的权重被加强。在将所有用户行为序列都转换成物品相关图中的边之后，全局的物品相关图就建立起来了。</p>
<p>3.图c采用随机游走的方式随机选择起始点，重新产生物品序列。</p>
<p>4.图d最终将这些物品序列输入word2vec模型，生成最终的物品Embedding向量。</p>
<p>随机游走的跳转概率，也就是到达节点vi后，下一步遍历vi的临接点vj的概率。如果物品的相关图是有向有权图，那么从节点vi跳转到节点vj的概率定义如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20190518114710294.png" alt="img"></p>
<p>权重Mij/点i的所有出边的权重之和</p>
<p><strong>Node2vec</strong></p>
<p><strong>同质性：</strong>距离相近节点的embedding应该尽量近似</p>
<p>eg. 节点u与其相连的节点s1、s2、s3、s4</p>
<p><strong>结构性：</strong>结构上相似的节点的embedding应该尽量接近，</p>
<p>eg. 节点u和节点s6</p>
<p><img src="https://img-blog.csdnimg.cn/2019051811474671.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lhc2luMA==,size_16,color_FFFFFF,t_70" alt="img"></p>
<p>控制bfs和dfs的概率</p>
<p><img src="https://img-blog.csdnimg.cn/20190518114815763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lhc2luMA==,size_16,color_FFFFFF,t_70" alt="img"></p>
<p><img src="https://img-blog.csdnimg.cn/20190518114839403.png" alt="img"></p>
<p><img src="https://img-blog.csdnimg.cn/20190518114939849.png" alt="img"></p>
<p>dtx指的是节点t到节点x的距离</p>
<p>参数p和q共同控制着随机游走的倾向性。</p>
<p>参数p被称为返回参数（return parameter），p越小，随机游走回节点t的可能性越大，node2vec就更注重表达网络的同质性，</p>
<p>参数q被称为进出参数（in-out parameter），q越小，则随机游走到远方节点的可能性越大，node2vec更注重表达网络的结构性，反之，当前节点更可能在附近节点游走。</p>
<p><strong>同质性相同的物品很可能是同品类、同属性、或者经常被一同购买的物品</strong></p>
<p><strong>结构性相同的物品则是各品类的爆款、各品类的最佳凑单商品等拥有类似趋势或者结构性属性的物品</strong>。</p>
<blockquote>
<p>阿里的Graph Embedding方法EGES</p>
</blockquote>
<p>2018年阿里公布了其在淘宝应用的Embedding方法EGES（Enhanced Graph Embedding with Side Information），其基本思想是在DeepWalk生成的graph embedding基础上引入补充信息。</p>
<p>新加入的物品，或者没有过多互动信息的长尾物品，推荐系统将出现严重的<strong>冷启动问题</strong>。为了使“冷启动”的商品获得“合理”的初始Embedding，阿里团队通过引入了更多<strong>补充信息</strong>来丰富Embedding信息的来源，从而使没有历史行为记录的商品获得Embedding。</p>
<p>生成Graph embedding的第一步是生成物品关系图，通过用户行为序列可以生成物品相关图，利用相同属性、相同类别等信息，也可以通过这些相似性建立物品之间的边，从而生成<strong>基于内容的knowledge graph</strong>。而基于knowledge graph生成的物品向量可以被称为补充信息（side information）embedding向量，当然，根据补充信息类别的不同，可以有多个<strong>side information embedding向量</strong>。</p>
<p>那么如何融合一个物品的多个embedding向量，使之形成物品最后的embedding呢？最简单的方法是在深度神经网络中加入average pooling层将不同embedding平均起来，阿里在此基础上进行了加强，对每个embedding加上了权重，如图7所示，对每类特征对应的Embedding向量，分别赋予了权重a0，a1…an。图中的Hidden Representation层就是对不同Embedding进行<strong>加权平均</strong>操作的层，得到加权平均后的Embedding向量后，再直接输入softmax层，这样通过梯度反向传播，就可以求的每个embedding的权重ai(i=0…n)。</p>
<p><img src="https://img-blog.csdnimg.cn/20190518115058979.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lhc2luMA==,size_16,color_FFFFFF,t_70" alt="img"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/08/03/word embedding/" data-id="cjzl0rmzh0007j4lba33hvtet" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/word-embedding/">word embedding</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/08/21/note of MySQL/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          note of MySQL
        
      </div>
    </a>
  
  
    <a href="/2019/08/03/Deep Learning for Entity Matching A Design Space Exploration/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Deep Learning for Entity Matching A Design Space Exploration</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/JAVA/">JAVA</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/">paper</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Entity-Matching/">Entity Matching</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL/">MySQL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/key/">key</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/word-embedding/">word embedding</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Entity-Matching/" style="font-size: 10px;">Entity Matching</a> <a href="/tags/MySQL/" style="font-size: 20px;">MySQL</a> <a href="/tags/key/" style="font-size: 10px;">key</a> <a href="/tags/word-embedding/" style="font-size: 10px;">word embedding</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">七月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/08/21/MySQL优化索引/">MySQL索引优化</a>
          </li>
        
          <li>
            <a href="/2019/08/21/KeyMiner Discovering Keys for Graphs/">KeyMiner Discovering Keys for Graphs</a>
          </li>
        
          <li>
            <a href="/2019/08/21/note of MySQL/">note of MySQL</a>
          </li>
        
          <li>
            <a href="/2019/08/03/word embedding/">word embedding</a>
          </li>
        
          <li>
            <a href="/2019/08/03/Deep Learning for Entity Matching A Design Space Exploration/">Deep Learning for Entity Matching A Design Space Exploration</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 HJJing<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>